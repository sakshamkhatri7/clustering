{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8fOjhzTX1O7J1JFlxNEFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Archit-29/Clustering/blob/main/Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFHkGxpP80Kf"
      },
      "outputs": [],
      "source": [
        "#IMPORT LIBARARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, MeanShift\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD DATASET\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "feature_names = iris.feature_names\n",
        "# Convert to DataFrame for easier handling\n",
        "iris_df = pd.DataFrame(X, columns=feature_names)"
      ],
      "metadata": {
        "id": "B8a5iJ-n9BiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING\n",
        "def preprocess_data(X, method):\n",
        "    if method == \"No Data Processing\":\n",
        "        return X\n",
        "    elif method == \"Using Normalization\":\n",
        "        scaler = StandardScaler()\n",
        "        return scaler.fit_transform(X)\n",
        "    elif method == \"Using Transform\":\n",
        "        # Example: Log transformation (make sure data is positive)\n",
        "        return np.log1p(X)\n",
        "    elif method == \"Using PCA\":\n",
        "        pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
        "        return pca.fit_transform(X)\n",
        "    elif method == \"Using T+N\":\n",
        "        # Combine normalization and another method (e.g., normalization)\n",
        "        scaler = StandardScaler()\n",
        "        return scaler.fit_transform(X)  # Can modify to add another transformation\n",
        "    elif method == \"Using T+N+PCA\":\n",
        "        # Normalize then apply PCA\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        pca = PCA(n_components=2)  # Adjust components\n",
        "        return pca.fit_transform(X_scaled)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown preprocessing method.\")\n"
      ],
      "metadata": {
        "id": "dAMfhU--9CkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLUSTERING METRICS\n",
        "def evaluate_clustering(X, n_clusters, algorithm):\n",
        "    try:\n",
        "        if algorithm == 'kmeans':\n",
        "            model = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        elif algorithm == 'hierarchical':\n",
        "            model = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "        elif algorithm == 'meanshift':\n",
        "            model = MeanShift()\n",
        "            labels = model.fit_predict(X)\n",
        "            n_clusters = None  # Set n_clusters to None for Mean Shift\n",
        "\n",
        "        labels = model.fit_predict(X)\n",
        "        silhouette = silhouette_score(X, labels)\n",
        "        calinski = calinski_harabasz_score(X, labels)\n",
        "        davies = davies_bouldin_score(X, labels)\n",
        "    except:\n",
        "        silhouette, calinski, davies = \"N/A\", \"N/A\", \"N/A\"\n",
        "\n",
        "    return silhouette, calinski, davies\n"
      ],
      "metadata": {
        "id": "4l3WpCv89FJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREPROCESSING MODELS\n",
        "preprocessing_methods = [\n",
        "    \"No Data Processing\",\n",
        "    \"Using Normalization\",\n",
        "    \"Using Transform\",\n",
        "    \"Using PCA\",\n",
        "    \"Using T+N\",\n",
        "    \"Using T+N+PCA\"\n",
        "]"
      ],
      "metadata": {
        "id": "JGwa-Bpa9Hfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dictionaries to store results for each clustering method\n",
        "kmeans_results = []\n",
        "hierarchical_results = []\n",
        "meanshift_results = []\n",
        "\n",
        "# Cluster numbers (c values) as subcolumns\n",
        "cluster_nums = [3, 4, 5]"
      ],
      "metadata": {
        "id": "aHKfJKQy9J9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CALCULATIONS\n",
        "# Evaluate for each preprocessing method and clustering algorithm\n",
        "for method in preprocessing_methods:\n",
        "    kmeans_row = []\n",
        "    hierarchical_row = []\n",
        "\n",
        "    for c in cluster_nums:\n",
        "        X_processed = preprocess_data(X, method)  # Apply preprocessing\n",
        "\n",
        "        # K-Means\n",
        "        silhouette, calinski, davies = evaluate_clustering(X_processed, c, 'kmeans')\n",
        "        kmeans_row.extend([silhouette, calinski, davies])\n",
        "\n",
        "        # Hierarchical Clustering\n",
        "        silhouette, calinski, davies = evaluate_clustering(X_processed, c, 'hierarchical')\n",
        "        hierarchical_row.extend([silhouette, calinski, davies])\n",
        "\n",
        "    kmeans_results.append(kmeans_row)\n",
        "    hierarchical_results.append(hierarchical_row)\n",
        "\n",
        "# Mean Shift (no cluster number needed, only metrics)\n",
        "for method in preprocessing_methods:\n",
        "    X_processed = preprocess_data(X, method)\n",
        "    silhouette, calinski, davies = evaluate_clustering(X_processed, None, 'meanshift')\n",
        "    meanshift_results.append([silhouette, calinski, davies])"
      ],
      "metadata": {
        "id": "I7PmxW9F9Mf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the results into DataFrames\n",
        "columns = pd.MultiIndex.from_product([[\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"], [\"c=3\", \"c=4\", \"c=5\"]])\n",
        "\n",
        "kmeans_df = pd.DataFrame(kmeans_results, index=preprocessing_methods, columns=columns)\n",
        "hierarchical_df = pd.DataFrame(hierarchical_results, index=preprocessing_methods, columns=columns)\n",
        "\n",
        "# Mean Shift table (no cluster numbers, just metrics)\n",
        "meanshift_df = pd.DataFrame(meanshift_results, index=preprocessing_methods, columns=[\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"])\n"
      ],
      "metadata": {
        "id": "97FcgiV49PEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISPLAY RESULT\n",
        "print(\"\\nK-Means Clustering Results:\")\n",
        "print(kmeans_df)\n",
        "\n",
        "print(\"\\nHierarchical Clustering Results:\")\n",
        "print(hierarchical_df)\n",
        "\n",
        "print(\"\\nMean Shift Clustering Results:\")\n",
        "print(meanshift_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llz8YM8G9Rxh",
        "outputId": "63874852-7639-4d14-8957-b0a32df48a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "K-Means Clustering Results:\n",
            "                    Silhouette                       Calinski-Harabasz  \\\n",
            "                           c=3         c=4       c=5               c=3   \n",
            "No Data Processing    0.551192  561.593732  0.666039          0.497643   \n",
            "Using Normalization   0.479881  157.360153  0.789363          0.385045   \n",
            "Using Transform       0.571878  502.487430  0.937543          0.392813   \n",
            "Using PCA             0.597676  693.708433  0.564816          0.557741   \n",
            "Using T+N             0.479881  157.360153  0.789363          0.385045   \n",
            "Using T+N+PCA         0.522791  180.975460  0.739126          0.445187   \n",
            "\n",
            "                                          Davies-Bouldin                        \n",
            "                            c=4       c=5            c=3         c=4       c=5  \n",
            "No Data Processing   529.529095  0.754140       0.493080  495.243414  0.819384  \n",
            "Using Normalization  206.680603  0.869779       0.345033  202.635850  0.943894  \n",
            "Using Transform      721.754299  1.028285       0.326710  715.167999  1.066897  \n",
            "Using PCA            719.123544  0.615069       0.510041  642.060666  0.752500  \n",
            "Using T+N            206.680603  0.869779       0.345033  202.635850  0.943894  \n",
            "Using T+N+PCA        263.884045  0.744669       0.411085  278.451395  0.780293  \n",
            "\n",
            "Hierarchical Clustering Results:\n",
            "                    Silhouette                       Calinski-Harabasz  \\\n",
            "                           c=3         c=4       c=5               c=3   \n",
            "No Data Processing    0.554324  558.058041  0.656256          0.488967   \n",
            "Using Normalization   0.446689  222.719164  0.803467          0.400636   \n",
            "Using Transform       0.571576  974.176228  0.628271          0.501012   \n",
            "Using PCA             0.598475  688.617548  0.560496          0.540977   \n",
            "Using T+N             0.446689  222.719164  0.803467          0.400636   \n",
            "Using T+N+PCA         0.511060  286.328664  0.705430          0.448735   \n",
            "\n",
            "                                          Davies-Bouldin                        \n",
            "                            c=4       c=5            c=3         c=4       c=5  \n",
            "No Data Processing   515.078906  0.795264       0.484383  488.484904  0.820417  \n",
            "Using Normalization  201.251454  0.978821       0.330587  192.681283  0.974249  \n",
            "Using Transform      786.663132  0.723808       0.429208  671.495769  0.843106  \n",
            "Using PCA            673.946264  0.654624       0.548784  665.883112  0.652573  \n",
            "Using T+N            201.251454  0.978821       0.330587  192.681283  0.974249  \n",
            "Using T+N+PCA        254.090094  0.722612       0.404169  254.996196  0.791250  \n",
            "\n",
            "Mean Shift Clustering Results:\n",
            "                     Silhouette  Calinski-Harabasz  Davies-Bouldin\n",
            "No Data Processing     0.685788         509.703427        0.388552\n",
            "Using Normalization    0.581750         251.349339        0.593313\n",
            "Using Transform        0.764932         951.609094        0.303047\n",
            "Using PCA              0.710311         565.734052        0.355059\n",
            "Using T+N              0.581750         251.349339        0.593313\n",
            "Using T+N+PCA          0.614520         283.005488        0.543999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ktfT4Ew9UBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}